---
layout: about
title: About
permalink: /
subtitle: Undergraduate Research Intern | Computer Architecture & AI Acceleration

profile:
  align: right
  image: me.jpg
  image_circular: false
  more_info: >
    <p> - 3rd Year, Electrical & Computer Engineering</p>
    <p> - Embedded & AI Systems Laboratory</p>
    <p> - Ajou University, Suwon, South Korea</p>

news: false
selected_papers: false
social: true 
---

I'm a third-year undergraduate student at Ajou University, deeply fascinated by **computer architecture** and **AI acceleration**. As a research intern in the Embedded and AI Systems Laboratory, I'm exploring how **HW/SW co-design** can unlock the potential of deep learning systems on specialized hardware.

My journey into this field began with Computer Systems Programming, where I became fascinated with the low-level world of how software commands orchestrate hardware. This experience sparked a deep interest in pushing performance to its limits at the hardware-software boundary. Now, as a research intern, my hands-on work in performance optimization has solidified that passion.   

This experience has convinced me that exploring custom accelerator design could be key to achieving better system-level efficiency



## **Current Research**

I'm currently working on **HW/SW optimization for Dynamic DNNs**, where I'm learning to port and optimize the **RISC-V Gemmini systolic array accelerator** within CPU-based runtimes like `llama.cpp`. This challenging project has taught me about the complexities of bridging specialized hardware and software frameworks through deep performance profiling and analysis.

I've also initiated the **ACE (AI/ML Accelerator Co-design Environment)**, a personal research endeavor where I'm systematically exploring GEMV (General Matrix-Vector Multiplication) acceleration. Starting from baseline software kernels, I'm progressing through SIMD-optimized CPU backends toward a final hardware implementation of an **INT8 systolic array on an FPGA**.

---

## **Research Interests & Learning Goals**

- **Hardware/Software Co-design**: Understanding how to optimize AI workloads across the full stack
- **Computer Architecture**: Building a strong foundation through my coursework in Computer Organization, with the goal of exploring RISC ecosystems, systolic arrays, and memory hierarchies.
- **AI/ML Acceleration**: Learning the fundamental principles of specialized architectures, including key techniques like quantization and structured sparsity.

---

## **Technical Skills**

- **Languages:** C/C++ (C++20), Python
- **Core Concepts:** Computer Architecture, Dynamic DNNs, Low-Level Optimization, Performance Profiling
- **Tools & Platforms:** VSCode, llama.cpp/ggml, GDB, Git, QEMU, FPGA development (learning)

---

## **Future Aspirations**

I'm planning to pursue graduate studies in computer architecture, with a focus on specialized computing systems for AI workloads. My goal is to contribute to the development of next-generation architectures that can efficiently handle the growing computational demands of AI applications.

---

*I'm always eager to learn more and discuss research ideas. Feel free to reach out if you'd like to connect!*
